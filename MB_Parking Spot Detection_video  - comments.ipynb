{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os, glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import mrcnn.config\n",
    "import mrcnn.utils\n",
    "#import keras.backend as\n",
    "from mrcnn.model import MaskRCNN\n",
    "from pathlib import Path\n",
    "from twilio.rest import Client\n",
    "import skimage.io\n",
    "import random \n",
    "\n",
    "# from moviepy.editor import VideoFileClip\n",
    "import imageio\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask RCNN Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskRCNNConfig(mrcnn.config.Config):\n",
    "    NAME = \"coco_pretrained_model_config\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "# COCO dataset has 80 classes (1 background class)    \n",
    "    NUM_CLASSES = 1 + 80  \n",
    "    DETECTION_MIN_CONFIDENCE = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO filter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter a list of Mask R-CNN detection results to get only the detected cars / trucks\n",
    "def get_car_boxes(boxes, class_ids):\n",
    "    car_boxes = []\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "# If the detected object isn't a bicycle/car/motorcycle/bus/truck, skip it\n",
    "        if class_ids[i] in [2, 3, 4, 6, 8]:\n",
    "            car_boxes.append(box)\n",
    "\n",
    "    return np.array(car_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories/Path/load/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\baghema\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\baghema\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\mrcnn\\model.py:775: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = Path(\".\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
    "\n",
    "# Video file or camera to process - set this to 0 to use your webcam instead of a video file\n",
    "VIDEO_SOURCE = \"parking.mp4\"\n",
    "\n",
    "# Create a Mask-RCNN model in inference mode\n",
    "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
    "\n",
    "# Load pre-trained model\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# Location of parking spaces\n",
    "parked_car_boxes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Position : 0\n",
      "1\n",
      "Position : 1000\n",
      "2\n",
      "Position : 2000\n",
      "3\n",
      "Position : 3000\n",
      "4\n",
      "Position : 4000\n",
      "5\n",
      "Position : 5000\n",
      "6\n",
      "Position : 6000\n",
      "7\n",
      "Position : 7000\n",
      "SENDING NOTIFICATION!\n",
      "8\n",
      "Position : 8000\n",
      "9\n",
      "Position : 9000\n",
      "10\n",
      "Position : 10000\n",
      "11\n",
      "Position : 11000\n",
      "12\n",
      "Position : 12000\n",
      "13\n",
      "Position : 13000\n",
      "14\n",
      "Position : 14000\n",
      "15\n",
      "Position : 15000\n",
      "16\n",
      "Position : 16000\n",
      "17\n",
      "Position : 17000\n",
      "18\n",
      "Position : 17680\n"
     ]
    }
   ],
   "source": [
    "# Load the video file we want to run detection on\n",
    "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "#video_capture.set(cv2.CAP_PROP_FPS, 0.1)\n",
    "\n",
    "#fps = FPS().start()\n",
    "# How many frames of video we've seen in a row with a parking space open\n",
    "free_space_frames = 0\n",
    "\n",
    "# Have we sent a notification alert yet?\n",
    "notification_sent = False\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "# Loop over each frame of video\n",
    "while video_capture.isOpened():\n",
    "    success, frame = video_capture.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    print(frame_num)\n",
    "    # Increasing the speed of video to be shown on the screen\n",
    "    video_capture.set(cv2.CAP_PROP_POS_MSEC, frame_num*1000)\n",
    "    print(\"Position : %d\" % video_capture.get(cv2.CAP_PROP_POS_MSEC))\n",
    "    frame_num += 1\n",
    "    \n",
    "    # Convert the image from BGR (used in open CV) to RGB\n",
    "    rgb_image = frame[:, :, ::-1]\n",
    "\n",
    "    # Run the image through the Mask R-CNN model to get results.\n",
    "    results = model.detect([rgb_image], verbose=0)\n",
    "\n",
    "    # Mask R-CNN assumes we are running detection on multiple images.\n",
    "    # Here we take just one result (one image/frame)\n",
    "    r = results[0]\n",
    "\n",
    "    # The r variable will now have the results of detection:\n",
    "    # - r['rois'] are the bounding box of each detected object\n",
    "    # - r['class_ids'] are the class id (type) of each detected object\n",
    "    # - r['scores'] are the confidence scores for each detection\n",
    "    # - r['masks'] are the object masks for each detected object (which gives you the object outline)\n",
    "\n",
    "    if parked_car_boxes is None:\n",
    "        # This is the first frame of video - assume all the cars detected are in parking spaces.\n",
    "        # Save the location of each car as a parking space box and go to the next frame of video.\n",
    "        parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "    else:\n",
    "        # We already know where the parking spaces are. Check if any are currently unoccupied.\n",
    "\n",
    "        # Get where cars are currently located in the frame\n",
    "        car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
    "\n",
    "        # See how much those cars overlap with the known parking spaces\n",
    "        overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)\n",
    "\n",
    "        # Assume no spaces are free until we find one that is free\n",
    "        free_space = False\n",
    "\n",
    "        # Loop through each known parking space box\n",
    "        for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
    "\n",
    "            # For this parking space, find the max amount it was covered by any\n",
    "            # car that was detected in our image (doesn't really matter which car)\n",
    "            max_IoU_overlap = np.max(overlap_areas)\n",
    "\n",
    "            # Get the top-left and bottom-right coordinates of the parking area\n",
    "            y1, x1, y2, x2 = parking_area\n",
    "\n",
    "            # Check if the parking space is occupied by seeing if any car overlaps\n",
    "            # it by more than 0.15 using IoU\n",
    "            if max_IoU_overlap < 0.15:\n",
    "                # Parking space not occupied! Draw a green box around it\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                # Flag that we have seen at least one open space\n",
    "                free_space = True\n",
    "            else:\n",
    "                # Parking space is still occupied - draw a red box around it\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "\n",
    "            # Write the IoU measurement inside the box\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
    "\n",
    "        # If at least one space was free, start counting frames\n",
    "        # This is so we don't alert based on one frame of a spot being open.\n",
    "        # This helps prevent the script triggered on one bad detection.\n",
    "        if free_space:\n",
    "            free_space_frames += 1\n",
    "        else:\n",
    "            # If no spots are free, reset the count\n",
    "            free_space_frames = 0\n",
    "\n",
    "        # If a space has been free for several frames, we are pretty sure it is really free!\n",
    "        if free_space_frames > 2:\n",
    "            # Write SPACE AVAILABLE!! at the top of the screen\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"SPACE IS AVAILABLE!\", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED)\n",
    "\n",
    "            # If we haven't sent a Notification yet, send it!\n",
    "            if not notification_sent:\n",
    "                print(\"SENDING NOTIFICATION!\")\n",
    "                #message = client.messages.create(\n",
    "                #    body=\"Parking space open - go go go!\",\n",
    "                #    from_=twilio_phone_number,\n",
    "                #    to=destination_phone_number\n",
    "                #)\n",
    "                notification_sent = True\n",
    "###Use tf.cast instead SENDING Notification!!!\n",
    "        # Show the frame of video on the screen\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up everything when finished\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
